{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_dist has a range of (0.0, 160.96000000000001)\n",
      "avg_rating_by_driver has a range of (1.0, 5.0)\n",
      "avg_rating_of_driver has a range of (1.0, 5.0)\n",
      "avg_surge has a range of (1.0, 8.0)\n",
      "city has a range of (u'Astapor', u'Winterfell')\n",
      "last_trip_date has a range of (u'2014-01-01', u'2014-07-01')\n",
      "phone has a range of (None, u'iPhone')\n",
      "signup_date has a range of (u'2014-01-01', u'2014-01-31')\n",
      "surge_pct has a range of (0.0, 100.0)\n",
      "trips_in_first_30_days has a range of (0, 125)\n",
      "ultimate_black_user has a range of (False, True)\n",
      "weekday_pct has a range of (0.0, 100.0)\n"
     ]
    }
   ],
   "source": [
    "def json_to_pd(fname):\n",
    "    '''read json file, convert to pandas dataframe'''\n",
    "    \n",
    "    with open(fname) as the_file:\n",
    "        dict_fname = json.load(the_file)\n",
    "    return pd.DataFrame(dict_fname)\n",
    "\n",
    "def get_range(column):\n",
    "    '''Accept dataframe column return tuple with max and min'''\n",
    "    return(min(column),max(column))\n",
    "\n",
    "fname='ultimate_data_challenge.json'\n",
    "train_df=json_to_pd(fname)\n",
    "\n",
    "for c in train_df.columns:\n",
    "    try:\n",
    "        print '{} has a range of {}'.format(c,get_range(train_df[c].values))\n",
    "    except:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 12 columns):\n",
      "avg_dist                  50000 non-null float64\n",
      "avg_rating_by_driver      49799 non-null float64\n",
      "avg_rating_of_driver      41878 non-null float64\n",
      "avg_surge                 50000 non-null float64\n",
      "city                      50000 non-null object\n",
      "last_trip_date            50000 non-null object\n",
      "phone                     49604 non-null object\n",
      "signup_date               50000 non-null object\n",
      "surge_pct                 50000 non-null float64\n",
      "trips_in_first_30_days    50000 non-null int64\n",
      "ultimate_black_user       50000 non-null bool\n",
      "weekday_pct               50000 non-null float64\n",
      "dtypes: bool(1), float64(6), int64(1), object(4)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#Look for missing values\n",
    "train_df.info(null_counts=True,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_dist</th>\n",
       "      <th>avg_rating_by_driver</th>\n",
       "      <th>avg_rating_of_driver</th>\n",
       "      <th>avg_surge</th>\n",
       "      <th>city</th>\n",
       "      <th>last_trip_date</th>\n",
       "      <th>phone</th>\n",
       "      <th>signup_date</th>\n",
       "      <th>surge_pct</th>\n",
       "      <th>trips_in_first_30_days</th>\n",
       "      <th>ultimate_black_user</th>\n",
       "      <th>weekday_pct</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.67</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.10</td>\n",
       "      <td>King's Landing</td>\n",
       "      <td>2014-06-17</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>2014-01-25</td>\n",
       "      <td>15.4</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>46.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Astapor</td>\n",
       "      <td>2014-05-05</td>\n",
       "      <td>Android</td>\n",
       "      <td>2014-01-29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.77</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Astapor</td>\n",
       "      <td>2014-01-07</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>2014-01-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.36</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.14</td>\n",
       "      <td>King's Landing</td>\n",
       "      <td>2014-06-29</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>2014-01-10</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.13</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.19</td>\n",
       "      <td>Winterfell</td>\n",
       "      <td>2014-03-15</td>\n",
       "      <td>Android</td>\n",
       "      <td>2014-01-27</td>\n",
       "      <td>11.8</td>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "      <td>82.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_dist  avg_rating_by_driver  avg_rating_of_driver  avg_surge  \\\n",
       "0      3.67                   5.0                   4.7       1.10   \n",
       "1      8.26                   5.0                   5.0       1.00   \n",
       "2      0.77                   5.0                   4.3       1.00   \n",
       "3      2.36                   4.9                   4.6       1.14   \n",
       "4      3.13                   4.9                   4.4       1.19   \n",
       "\n",
       "             city last_trip_date    phone signup_date  surge_pct  \\\n",
       "0  King's Landing     2014-06-17   iPhone  2014-01-25       15.4   \n",
       "1         Astapor     2014-05-05  Android  2014-01-29        0.0   \n",
       "2         Astapor     2014-01-07   iPhone  2014-01-06        0.0   \n",
       "3  King's Landing     2014-06-29   iPhone  2014-01-10       20.0   \n",
       "4      Winterfell     2014-03-15  Android  2014-01-27       11.8   \n",
       "\n",
       "   trips_in_first_30_days  ultimate_black_user  weekday_pct  target  \n",
       "0                       4                 True         46.2       1  \n",
       "1                       0                False         50.0       0  \n",
       "2                       3                False        100.0       0  \n",
       "3                       9                 True         80.0       1  \n",
       "4                      14                False         82.4       0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are three features with missing values, Two are numeric and one is categorical.  \n",
    "# To make a decision on how to deal with these values, we need the target variable to judge \n",
    "# impact\n",
    "\n",
    "# To get target, use last_trip_date-start_date in months to be greater than 5.  Per\n",
    "#the instructions a user is retained if he has taken a trip in the preceeding 30 days.  That means that he is retained in month \n",
    "# six if he takes a ride in month 5.\n",
    "\n",
    "# Because of the specifics of this dataset, we can use simple math (all signups occurred in January, so anyone that took a last ride\n",
    "# in June or later was retained for six months)\n",
    "\n",
    "# Note: this is a very important assuption,as the results would be completely different if you\n",
    "#used a different retention rule.  As an example, I could have used time delta of 180 days \n",
    "#to represent a customer retained for six months.\n",
    "\n",
    "\n",
    "def make_date_tuple(string):\n",
    "    tmp=string.split('-')\n",
    "    return (int(tmp[0]),int(tmp[1]),int(tmp[2]))\n",
    "\n",
    "train_df['st_date']=train_df.signup_date.apply(make_date_tuple)\n",
    "train_df['lr_date']=train_df.last_trip_date.apply(make_date_tuple)\n",
    "train_df['months_retained']=train_df.apply(lambda x: x.lr_date[1]-x.st_date[1],axis=1)\n",
    "train_df['target']=train_df.apply(lambda x: 1 if x.months_retained >=5 else 0,axis=1)\n",
    "train_df.drop(['st_date','lr_date','months_retained'],inplace=True,axis=1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a target variable, it is now possible to decide how to treat missing values.  Look first at phone type.  Note: there are only two types in the data: iPhone and Android, and would really reflect differences in app quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44893297091 0.209426174943 0.335858585859\n"
     ]
    }
   ],
   "source": [
    "iphone=train_df.loc[train_df.phone=='iPhone','target'].mean()\n",
    "android=train_df.loc[train_df.phone=='Android','target'].mean()\n",
    "none=train_df.loc[(train_df.phone!='Android') & (train_df.phone!='iPhone'),'target'].mean()\n",
    "print iphone,android,none"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a large difference between the Android and iPhonoe customers.  First this means that we can't simply chose a phone type for missing values.  Nans will be filled in with a string \"None given\".  Additionally, this is an import thing to pass along to the client.  THere should be no difference in customer retention based on phone type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -0.01182859]\n",
      " [-0.01182859  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "tmp=train_df.copy()\n",
    "tmp.dropna(axis=0,inplace=True)\n",
    "print np.corrcoef(tmp.target,tmp.avg_rating_of_driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2 dimensional correlation between average rating of driver to target is low, so I am filling in the missing values with the average.  I expect this to have minimal impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.60172035227 4.77644589215\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 13 columns):\n",
      "avg_dist                  50000 non-null float64\n",
      "avg_rating_by_driver      50000 non-null float64\n",
      "avg_rating_of_driver      50000 non-null float64\n",
      "avg_surge                 50000 non-null float64\n",
      "city                      50000 non-null object\n",
      "last_trip_date            50000 non-null object\n",
      "phone                     50000 non-null object\n",
      "signup_date               50000 non-null object\n",
      "surge_pct                 50000 non-null float64\n",
      "trips_in_first_30_days    50000 non-null int64\n",
      "ultimate_black_user       50000 non-null bool\n",
      "weekday_pct               50000 non-null float64\n",
      "target                    50000 non-null int64\n",
      "dtypes: bool(1), float64(6), int64(2), object(4)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "avg_of_driver=tmp.avg_rating_of_driver.mean()\n",
    "\n",
    "avg_by_driver=tmp.avg_rating_by_driver.mean()\n",
    "print avg_of_driver,avg_by_driver\n",
    "\n",
    "train_df['avg_rating_of_driver'].fillna(avg_of_driver,inplace=True)\n",
    "train_df['avg_rating_by_driver'].fillna(avg_by_driver,inplace=True)\n",
    "train_df['phone'].fillna('Missing Phone Type',inplace=True)\n",
    "train_df.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.6% of users were retained.\n"
     ]
    }
   ],
   "source": [
    "#Question1:  What percentage of the users were retained?\n",
    "print '{:4.1f}% of users were retained.'.format(train_df.target.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    0\n",
      "2    0\n",
      "3    1\n",
      "4    0\n",
      "Name: target, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_dist</th>\n",
       "      <th>avg_rating_by_driver</th>\n",
       "      <th>avg_rating_of_driver</th>\n",
       "      <th>avg_surge</th>\n",
       "      <th>surge_pct</th>\n",
       "      <th>trips_in_first_30_days</th>\n",
       "      <th>ultimate_black_user</th>\n",
       "      <th>weekday_pct</th>\n",
       "      <th>phone_Android</th>\n",
       "      <th>phone_Missing Phone Type</th>\n",
       "      <th>phone_iPhone</th>\n",
       "      <th>city_Astapor</th>\n",
       "      <th>city_King's Landing</th>\n",
       "      <th>city_Winterfell</th>\n",
       "      <th>signup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.67</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.10</td>\n",
       "      <td>15.4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>46.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.77</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.36</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.14</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.13</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.19</td>\n",
       "      <td>11.8</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>82.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_dist  avg_rating_by_driver  avg_rating_of_driver  avg_surge  surge_pct  \\\n",
       "0      3.67                   5.0                   4.7       1.10       15.4   \n",
       "1      8.26                   5.0                   5.0       1.00        0.0   \n",
       "2      0.77                   5.0                   4.3       1.00        0.0   \n",
       "3      2.36                   4.9                   4.6       1.14       20.0   \n",
       "4      3.13                   4.9                   4.4       1.19       11.8   \n",
       "\n",
       "   trips_in_first_30_days  ultimate_black_user  weekday_pct  phone_Android  \\\n",
       "0                       4                    1         46.2              0   \n",
       "1                       0                    0         50.0              1   \n",
       "2                       3                    0        100.0              0   \n",
       "3                       9                    1         80.0              0   \n",
       "4                      14                    0         82.4              1   \n",
       "\n",
       "   phone_Missing Phone Type  phone_iPhone  city_Astapor  city_King's Landing  \\\n",
       "0                         0             1             0                    1   \n",
       "1                         0             0             1                    0   \n",
       "2                         0             1             1                    0   \n",
       "3                         0             1             0                    1   \n",
       "4                         0             0             0                    0   \n",
       "\n",
       "   city_Winterfell signup  \n",
       "0                0     25  \n",
       "1                0     29  \n",
       "2                0     06  \n",
       "3                0     10  \n",
       "4                1     27  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prep model columns.\n",
    "# categorical variables will be city and phone\n",
    "#last_trip_date will be dropped as that will cause leakage to the target\n",
    "#signup date will be converted to an integer that represents the day (month and year are common across all lines)\n",
    "\n",
    "train_df=pd.get_dummies(train_df,columns=['phone','city'])\n",
    "train_df['signup']=train_df.apply(lambda x: x.signup_date.split('-')[2],axis=1)\n",
    "target=train_df.target\n",
    "train_df.drop(['last_trip_date','signup_date','target'],inplace=True,axis=1)\n",
    "train_df['ultimate_black_user']=train_df['ultimate_black_user'].astype(int)\n",
    "print target[:5]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*:  In the interest of time, two decisions were made that drive the overall solution:  \n",
    "\n",
    " 1) A single classifier is optimized, fit, and evaluated.  However, the code is written so\n",
    "    other classifiers can be tried by simply supplying a difference parameter set.  All\n",
    "    metrics will be reported on a similar basis.\n",
    "\n",
    " 2) RandomizedSearch is used rather than grid search.  This data is relatively small, but\n",
    "   in a larger dataset, GridSearch can be prohibitive from a computational standpoint.  The code is written so that is an easy change to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[Parallel(n_jobs=5)]: Done   1 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=5)]: Done   2 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=5)]: Done   3 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=5)]: Done   4 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=5)]: Done   6 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=5)]: Done   7 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=5)]: Done   9 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=5)]: Done  10 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=5)]: Done  11 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=5)]: Done  12 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=5)]: Done  13 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=5)]: Done  14 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=5)]: Done  15 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=5)]: Done  16 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=5)]: Done  17 out of  25 | elapsed:   18.4s remaining:    8.6s\n",
      "[Parallel(n_jobs=5)]: Done  18 out of  25 | elapsed:   19.4s remaining:    7.5s\n",
      "[Parallel(n_jobs=5)]: Done  19 out of  25 | elapsed:   19.5s remaining:    6.1s\n",
      "[Parallel(n_jobs=5)]: Done  20 out of  25 | elapsed:   22.7s remaining:    5.6s\n",
      "[Parallel(n_jobs=5)]: Done  21 out of  25 | elapsed:   23.2s remaining:    4.3s\n",
      "[Parallel(n_jobs=5)]: Done  22 out of  25 | elapsed:   24.9s remaining:    3.3s\n",
      "[Parallel(n_jobs=5)]: Done  23 out of  25 | elapsed:   25.9s remaining:    2.2s\n",
      "[Parallel(n_jobs=5)]: Done  25 out of  25 | elapsed:   28.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done  25 out of  25 | elapsed:   28.6s finished\n",
      "Random Forrest Classifier has a roc_aucscore_of 0.83924\n",
      "Random Forrest ClassifierBest Params {'min_samples_leaf': 3, 'n_estimators': 200, 'max_features': 'log2', 'criterion': 'gini', 'min_samples_split': 4, 'max_depth': 6}\n",
      "Random Forrest ClassifierBest Score 0.837205615348\n",
      "Random Forrest Classifier_score 0.839239399035\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc,roc_auc_score\n",
    "import sklearn.cross_validation as cv\n",
    "import sklearn.feature_selection as feature_selection\n",
    "\n",
    "def randomly_optimize_classifier(clf,name,train_df,target,param_search,\\\n",
    "                n_iter=10,scoring='roc_auc',cv_num=5,verbose=50,\\\n",
    "                random_state=0,test_size=0.33,n_jobs=2):#5\n",
    "    \n",
    "    tmp_df=train_df.copy()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\\\n",
    "        train_df, target, test_size=test_size,random_state=random_state)\n",
    "\n",
    "    clf=RandomizedSearchCV(clf,param_search,scoring=scoring,\\\n",
    "        cv=cv_num,n_iter=n_iter,verbose=verbose,n_jobs=n_jobs)\n",
    "    \n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    rocky=roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n",
    "    print '{} has a roc_aucscore_of {:6.5f}'.format(name,rocky)\n",
    "    \n",
    "    print name+'Best Params',clf.best_params_\n",
    "    print name+'Best Score',clf.best_score_\n",
    "    print name+'_score',clf.score(X_test, y_test)\n",
    "    print '\\n'\n",
    "    \n",
    "    \n",
    "\n",
    "    return clf,X_train,X_test,y_train,y_test\n",
    "        \n",
    "    \n",
    "n_iter=5   \n",
    "rf_name='Random Forrest Classifier'\n",
    "\n",
    "rf_param_search={'n_estimators':[10,50,100,200,400],\n",
    "                 'criterion':['gini'],\n",
    "                 'max_features':['sqrt','log2'],\n",
    "                 'max_depth':[2,4,6],\n",
    "                 'min_samples_split':[2,4,6],\n",
    "                 'min_samples_leaf':[1,2,3]}\n",
    "\n",
    "\n",
    "rf=RandomForestClassifier()\n",
    "rf_opt,X_train,X_test,y_train,y_test=randomly_optimize_classifier(rf,rf_name,train_df,\\\n",
    "        target,rf_param_search,n_iter=n_iter,n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=6, max_features='log2', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=400, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: Randomized Optimizer does not return feature importances.  It is necessary to fit a true\n",
    "# RF classifers to get them.  Using the best parameters from above:\n",
    "\n",
    "rf=RandomForestClassifier(min_samples_leaf=1, n_estimators=400, max_features='log2',\\\n",
    "                criterion='gini', min_samples_split=4, max_depth=6)\n",
    "\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feats</th>\n",
       "      <th>importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>avg_rating_by_driver</td>\n",
       "      <td>0.196267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>surge_pct</td>\n",
       "      <td>0.156400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>city_King's Landing</td>\n",
       "      <td>0.124138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>weekday_pct</td>\n",
       "      <td>0.107302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avg_surge</td>\n",
       "      <td>0.106198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>phone_iPhone</td>\n",
       "      <td>0.063101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ultimate_black_user</td>\n",
       "      <td>0.061584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>phone_Android</td>\n",
       "      <td>0.060145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>trips_in_first_30_days</td>\n",
       "      <td>0.053114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>city_Astapor</td>\n",
       "      <td>0.033529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>city_Winterfell</td>\n",
       "      <td>0.014797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>avg_dist</td>\n",
       "      <td>0.011234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avg_rating_of_driver</td>\n",
       "      <td>0.008614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>signup</td>\n",
       "      <td>0.003176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>phone_Missing Phone Type</td>\n",
       "      <td>0.000401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feats  importances\n",
       "1       avg_rating_by_driver     0.196267\n",
       "4                  surge_pct     0.156400\n",
       "12       city_King's Landing     0.124138\n",
       "7                weekday_pct     0.107302\n",
       "3                  avg_surge     0.106198\n",
       "10              phone_iPhone     0.063101\n",
       "6        ultimate_black_user     0.061584\n",
       "8              phone_Android     0.060145\n",
       "5     trips_in_first_30_days     0.053114\n",
       "11              city_Astapor     0.033529\n",
       "13           city_Winterfell     0.014797\n",
       "0                   avg_dist     0.011234\n",
       "2       avg_rating_of_driver     0.008614\n",
       "14                    signup     0.003176\n",
       "9   phone_Missing Phone Type     0.000401"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df=pd.DataFrame()\n",
    "feature_df['feats']=train_df.columns\n",
    "feature_df['importances']=rf.feature_importances_\n",
    "feature_df.sort_values('importances',ascending=False,inplace=True)\n",
    "feature_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above shows the features for the random forrest model created ranked by importance.  Intuitively, much of it make some sense.  A the rating by the driver represents a loose analysis of the customer's behaviour (did she tip well? was he friendly? etc.) all of which can reflect a customer's experience on the trip.  Surge pricing shows up twice in the top ten, weekday percentage has a likely correlation with business use, etc.  \n",
    "\n",
    "However, there are two surprising things in the list.  King's Landing is a topve feature and Astapor and Winterfell are significantly less important.   Looking at the relative representations in the data(below) it is clear that King's Landing is the lowest represented city.  From this data, we can't conclude why, but it is worth highlighting to the client.  They should examine the differences between cities and apply any learnings from King's Landing to the other cities.\n",
    "\n",
    "Finally, average rating of driver, which is a measure of the average ranking a driver recieves from custmomers is quite low (nearly zero impact.)  This supports the idea that for this case, direct customer feedback is less important than measuring their actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winterfell is 46.7% of the data\n",
      "Astapor is 33.1% of the data\n",
      "King's Landing is 20.3% of the data\n"
     ]
    }
   ],
   "source": [
    "print '{} is {:4.1f}% of the data'.format('Winterfell',100*train_df.city_Winterfell.mean())\n",
    "print '{} is {:4.1f}% of the data'.format('Astapor',100*train_df.city_Astapor.mean())\n",
    "print '{} is {:4.1f}% of the data'.format(\"King's Landing\",100*train_df[\"city_King's Landing\"].mean())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
